---
title: "The KidsWords Project"
subtitle: "Exploratory Data Analysis with R" 
author: "Thomas Klee"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output: 
  html_document:
    theme: readable
    toc: true
    number_sections: true
    toc_float: true
    fig_caption: yes
---

```{r include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

![](images/CMDS1836_Kids_Word_Banner.jpg)

# Introduction

The KidsWords project, which I'll describe shortly, was designed to:

- develop norms for a standardised measure of early language development based on a representative cross-section of children living in Aotearoa/New Zealand; and

- examine associations between measures of early language development, child, family and demographic variables.

This project involved observational rather than experimental research, but both kinds of investigations involve exploratory data analyses of some kind in the early stages, before the research questions that were initially posed can be addressed. What do we mean by by _exploratory data analysis_? [Wickham and Grolemund (2017)](https://r4ds.had.co.nz/exploratory-data-analysis.html) define it as using "visualisation and transformation to explore your data in a systematic way".

## Why was this written?

With this document, the goals are to:

- provide research students and others with how one researcher (me) explored real data from a large-scale research project; and

- provide examples of how the figures for that project were created using R. 

When we read a research article, it usually contains one or more figures---visualizations of certain aspects of the data---but typically we don't get to hear what the researcher was thinking as they explored their data. Instead, what we see in the journal article is the finished product---the end result of the data preparation and analysis pipeline, driven in part by the journal's page/word length restrictions. So the intention here is to reveal some of my thinking as I progressed from one analysis to the next, while acknowledging that there is more than one way to explore data. 

Something else we aren't normally told when reading a research article is _how_ the researcher constructed each figure or executed each statistical analysis. Sometimes authors don't even report what statistical software package was used for data analysis. Instead, the Methods section of articles typically only offer terse descriptions like "a paired t-test was done" or a "linear mixed effects model was conducted". 

Thankfully, things are beginning to change for the better. Many funding agencies and some journals now require researchers to upload their (raw or cleaned) data to a publicly accessible data repository such as [Open Science Framework](https://osf.io), [Dataverse](http://dataverse.org/), [FigShare](http://figshare.com) or [GitHub](https://github.com/), so that others can download and analyse the data for checking and further data analyses. In addition, the specific code or instructions (e.g., R scripts) used to perform the analyses reported can be uploaded to the web site. 

I'm hopeful that the day will come when we look back at the era when this was not routinely done as being out-of-step with modern science. Researchers who have a healthy skepticism about what they read is one thing---being able to question the conclusions of research studies has always driven science forward---but having access to the data and the scripts with which those conclusions were drawn is another thing. The move toward open science empowers people to not only question published conclusions but also potentially improve on the data analyses done to reach those conclusions. 

## Who was this written for?

I've written this for those who have little if any experience of doing research or creating plots with R. But it isn't an introduction to R itself, since many excellent resources are already available for that. I'll point you to some that have been useful to me at the end of the document (to do...). 

Since this is an HTML file, the length of text lines will automatically adjust when you view it on different devices. However, the text appearing in boxes sometimes wraps if the screen display is too small, and might not be clear, so I recommend viewing this on a large enough screen so that wrapping doesn't interfere with the text in the boxes.

# Data analysis toolbox

Some of the plots below were created using R's wonderful `ggplot2` package, while others were made with base with R's `plot` command or other R packages. The specific approach used to create each plot is specified for each plot. This document doesn't go into detailed explanations of what each line of R code does, but one of the best resources I know for learning more about the R code used for making graphs is Winston Chang's [R Graphics Book](https://r-graphics.org), the contents of which are freely available online or for purchase as book. I've used it since the first edition came out and highly recommend it. Another good book for R-based graphics is Kieran Healey's book, [Data Visualization: a Practical Introduction](https://www.bookdepository.com/Data-Visualization/9780691181622).

The sets of instructions (chunks of R code) for making each plot are presented below in boxes with grey backgrounds along with the plot resulting from that code. R usually generates warnings for things like missing data, but these warnings have been suppressed to make the display more readable. However, it's best not to suppress warnings so that you're aware of any potential problems with your output, such as that missing data were handled differently than what you wanted. Each R package is loaded as needed to show you which packages were used for each plot. In practice, though, each R package only needs to be loaded once at the beginning of an R session using the `library()` function.

[R](https://www.r-project.org) was used to process the raw data downloaded from an SQL database on the server hosting the KidsWords website and a local database on my computer. R was used to analyse the data and create plots and tables. [R Markdown](https://rmarkdown.rstudio.com/lesson-1.html) was used as the markup language in the document you're reading and [RStudio](http://www.rstudio.com) was used, via the `knitr` package to render what I wrote into HTML without having to use any HTML code. RStudio was the tool that integrated all this and uploaded it to the [KidsWords repository on GitHub](https://github.com/thomasklee). 

The data analyses and plots presented in this document are not in final form. They are suggestive of the final results but presented here for the purpose of illustrating how the plots were made. The source document (an R Markdown file) behind the HTML file you're reading does not contain any numbers or plots copied ot er-typed into it from other sources. The source document was written dynamically, meaning that if something gets changed in the data pipeline (e.g., a data point or coding error gets corrected), all the results and plots get updated automatically without any intervention from me. _The last two sentences are worth reading again!_ Thinking about your data preparation, data analysis and manuscript preparation work flow before you begin your project will pay off in the long run. This is another reason for using R, RStudio and a markup language like R Markdown or LaTeX as you write. If you want to see the source document that generated the HTML document you're reading, it will be uploaded to GitHub soon (to do...). 

Let's get started.

# The data

Let's briefly describe the data and where it came from. Parents throughout New Zealand wishing to participate in the KidsWords project were sent a username and password. Upon receiving it, they could log into a secure website to complete an on-line version of the New Zealand adaptation of the [MacArthur-Bates Communicative Development Inventory: Words and Sentences (NZ CDI:WS)](https://github.com/thomasklee/KidsWords/blob/master/PDFs/NZ-CDI-2012.pdf) and a [Parent Questionnaire (PQ)](https://github.com/thomasklee/KidsWords/blob/master/PDFs/KidsWords_parent_questionnaire.pdf) designed to ascertain selected child, family and demographic information. 

Raw CDI and PQ data were exported as text (CSV) files from the KidsWords SQL database and then imported into R for processing and analysis. I followed Broman and Woo's (2018) principles for "organizing spreadsheet data to reduce errors and ease later analyses" in their excellent paper in [The American Statistician](https://tohdos.ca/wp-content/uploads/2017/11/Broman-TAS-2018-Data-Organization-in-Spreadsheets.pdf), even though I used R instead of spreadsheet software. Most of the principles in their paper are likely to be things you already do when you construct your own data files, but it's well worth reading just the same (and recommending to your research students).

The first step in exploring data is to import the raw data files from your research project into R. The steps taken to prepare or "clean" questionnaire data so that it can be analysed is something we won't go into here, but the approach we took was guided by a paper written by Wickham (2014) in the [Journal of Statistical Software](https://www.jstatsoft.org/article/view/v059i10/). See [Grolemund and Wickam (2017)](https://r4ds.had.co.nz/introduction.html) for a graph illustrating this process. 
Let's see how this was done with the KidsWords data. The raw data downloaded from the KidsWords web site were first processed with three "dataprep" scripts that you can view or download from the [KidsWords repository  on GitHub](https://github.com/thomasklee/KidsWords/tree/master/analysis). The idea is to never make any changes to the raw data files even if they contain errors. Instead, changes are made to imported data using R scripts in order to get the raw data into shape for data analysis. Turning _raw_ data into _analysable_ data results in **data frames** that can then be used by other scripts for data analysis. (Eventually, a cleaned set of exported text (CSV) files will be uploaded to a public data repository so that others can make use of the data.)

The block of R code below begins by loading the `tidyverse` package, since we'll be using functions from that package frequently. Three data frames, `requests`, `CDIPQ` and `xs`, are then created. The first data frame, `requests`, was created by importing text data from a CSV file exported from a second database on my computer. That database kept track of parents who expressed an interest in the project, along with login credentials given to them to access the data entry system on the KidsWords web site should they decide to participate. The second data frame, `CDIPQ`, loads data from a CSV file containing parents' responses to NZ CDI:WS and PQ. 

The full data set consists of cross-sectional and longitudinal data, but since we only need cross-sectional data for the plots below, a third data frame, `xs`, was created by filtering `CDIPQ` for (1) data entered on the first occasion (`session == 1`), (2) children 16- through 30-months of age (`camos >= 16 & camos <= 30`) and (3) those whose main or only language was reported to be English (`mono_env == "yes"`). Further details of participants and the data set are described in the main manuscript. 

```{r data, message=FALSE, warning=FALSE}

# load package
library(tidyverse)

# load data into a data frame called requests
requests <- read.csv("analysis/data/qry_requests_20151008.csv")

# load data into a data frame called CDIPQ
CDIPQ <- read.csv("analysis/data/data_CDIPQ.csv")

# filter a subset of data from CDIPQ into a new data frame called xs
xs <- CDIPQ %>% 
  filter(session == 1,  camos >= 16 & camos <= 30, mono_env == "yes")
```

Most of the plots below will be based on the cross-sectional subset, `xs` (_N_ = `r nrow(xs)`) of the full data set, `CDIPQ` (_N_ = `r nrow(CDIPQ)`) using the `filter()` function of the R's `dplyr` package that is bundled with other packages in the `tidyverse` package. Let's take a look at the first 10  rows of the `xs` data frame and some of the variables we'll be using here. Variable names appear in the first row of the output below and participant ID codes appear in the first column. 

```{r, message=FALSE, warning=FALSE, cache=TRUE}
xs_select <- select(xs, PID, camos, wordtotal, csex, cbirth_weight_grams, 
                    cbirth_order, region)
head(xs_select, 10)
```

# The plots

## Distribution of participation requests

The first question researchers thinking of doing a study such as this might ask is, _How long did it take to recruit participants to this project?_ Let's create a plot to find out. To do this, we'll use the `requests` data frame we created above. That data frame contains two variables: an identififation number for each individual who requested to participate in the study and the date emailed a password to the parent. The box below shows you the structure of the data frame, followed by the first 10 rows of the data frame. If you're new to R, a **data frame** is a special kind of **object** that gets created from a set of data (that may have been imported from a spreadsheet, for example). Objects such as this are listed in the Enviroment tab of RStudio and contain data that can be viewed, described and analysed.

```{r}

# load package
library(tidyverse)

# display internal structure of the data frame
str(requests)

# display first 10 rows of the data frame
head(requests, 10)
```

From this, we can see that the `requests` data frame contains `r nrow(requests)` observations (i.e., participant requests) and two variables: Refno_pwd and Upload_date_pwd. The output also tells us that values of Refno_pwd are defined as integers (`int`), while values of Upload_date_pwd are defined as a categorical variable (`Factor`). In the output below that, we see the contents of the first 10 rows of data and line numbers.

We'll use base R's `plot()` function to make the graph below. All the code for making this plot appears in the grey box below. The output resulting from the code, a **cumulative frequency plot**, appears below the code box. 

```{r, message=FALSE, warning=FALSE, out.width = '80%', fig.asp = 1.0, fig.align = 'center', fig.cap = 'Cumulative number of valid requests to participate'} 

# load packages
library(tidyverse)
library(lubridate)

# construct a graph of the cumulative frequency of requests
# from parents to participate in the project.

# convert character strings to date class
reqdate <- dmy(requests$Upload_date_pwd)

# remove 8 records from database test phase
requests <- filter(requests, reqdate >= "2012-10-10")

# create table
request_table <- table(format(reqdate, "%Y-%m"))

# count cumulative number of requests
cumfreq <- cumsum(request_table)

# create plot  
plot(cumfreq, xlab = "Month of Data Collection", 
     ylab = "Valid Requests to Participate")
lines(cumfreq)
```

## Distribution of birth weight

Why plot the distribution of children's birth weights? The children in the sample were not randomly selected from the population since there wasn't a mechanism available to us for doing that in New Zealand. However, since one of the project's main goals was to develop a population model of children's early language development (e.g., percentile tables for measures of early vocabulary and grammar), we need to know whether our sample is representative of the larger population. 

One way of doing this is to compare relevant demographic characteristics of the sample with those of the population. However, this can only be done for the same measures available in the sample and the population. Anticipating this during the study's planning stage, and knowing that the best source of population-level data available are national census data, we designed as many most of the demographic questions on our Parent Questionnaire using identical wording to questions asked by [Stats NZ](https://www.stats.govt.nz) for the 2013 New Zealand Census. 

In looking at which variables from our study could be compared to census-level results to gauge how representative our sample was, three variables come to mind: the child's birth weight, geographical region of residence and parent education level. Let's see how each of those compares with the national census data (to do...).

The `ggplot2` package was used to make a **histogram** of children's reported birth weight. To plot any histogram, a decision has to be made about the bin width of the dependent variable--in this case birth weight. While this is easy to do for categorical variables, like sex or birth order, making a histogram of a continuous variable like birth weight requires a decision about how to divide a continuous variable into somewhat arbitrary categories, or _bins-. In the example below, we specified a bin width of 500 grams: `scale_x_continuous("\nBirth weight (grams)", breaks = seq(500, 5500, 500))`.

```{r, message=FALSE, warning=FALSE, cache=TRUE}

# load packages
library(ggplot2)
library(ggthemes)
library(RColorBrewer)

# create plot
ggplot(xs, aes(x = cbirth_weight_grams)) +
  geom_histogram(binwidth = 100, fill = "cornsilk", colour = "grey60") +
  scale_x_continuous("\nBirth weight (grams)", breaks = seq(500, 5500, 500)) +
  theme_few() +
  labs(caption = "Source: KidsWords project")
```

An alternative to binning a continuous variable is to plot a **kernel density curve**. We've done that in the next figure and overlaid it on the histogram. These are probability curves, with the area under the curve equal to 1, and they are sometimes referred to as smoothed histograms.

We also added a vertical line indicating the median birth weight of children in the sample (`r median(xs$cbirth_weight_grams, na.rm = TRUE)` grams). The instruction to include the median value was specified with the `geom_vline( )` function. 

```{r, message=FALSE, warning=FALSE, cache=TRUE}

library(ggplot2)
library(ggthemes)
library(RColorBrewer)

# create plot
ggplot(xs, aes(x = cbirth_weight_grams, y = ..density..)) +
  geom_histogram(binwidth = 100, fill = "cornsilk", colour = "grey60") +
  geom_line(stat = "density") + 
  scale_x_continuous("\nBirth weight (grams)", breaks = seq(500, 5500, 500)) + 
  geom_vline(xintercept = median(xs$cbirth_weight_grams, na.rm = TRUE)) +
  scale_y_continuous("Density\n") + 
  theme_few() +
  labs(caption = "Source: KidsWords project")
```

The next step is to see how the distribution of birthweights in our sample compares with that of the New Zealand population. After the next plot, we'll do that.

**Kernel density curves** are also useful for comparing subgroups. Let's look at how girls and boys compare using this kind of plot.

```{r, message=FALSE, warning=FALSE, cache=TRUE}

library(ggplot2)
library(RColorBrewer)

# calculate median birth weight of girls and boys
df_girls <- filter(xs, csex == "Girl")
df_boys <- filter(xs, csex == "Boy")
wt_girls <- median(df_girls$cbirth_weight_grams, na.rm = TRUE)
wt_boys <- median(df_boys$cbirth_weight_grams, na.rm = TRUE)

# create plot
ggplot(xs, aes(x = cbirth_weight_grams, fill = csex)) +
  geom_density(alpha = 0.2) +
  geom_vline(xintercept = wt_girls, colour = "#0072B2") +
  geom_vline(xintercept = wt_boys, colour = "#D55E00") +
  theme_bw() +
  labs(caption = "Source: KidsWords project")
```

We see from the plot above that the two distributions overlap to a large degree, with boys' birth weights shifted slightly to the right. The appearance of this plot differs from previous ones in that the variable name is used to label the x-axis since axis labels default to variable names in R unless otherwise specified. And unlike in previous plots, light grey reference lines were added to the backgound of the plot. This grid and other changes to the appearance of the graph were specified using ggplot's `theme_bw()` function. Previous plots used the `theme_few()` function from the `ggthemes` package.

How does our sample compare to the population? The reason for asking is to help us decide whether our sample (_N_ = `r nrow(xs)`) might have been affected by [self-selection bias](http://sphweb.bumc.bu.edu/otlt/MPH-Modules/EP/EP713_Bias/EP713_Bias_print.html). This is a distinct possibility since our sample was recruited by making the public aware of the project, but whether they actually paricipated or not was their decision.

In its [Report on Maternity](https://www.health.govt.nz/publication/report-maternity-2010), New Zealand's Ministry of Health stated that, for the calendar 2010,

- _the average birthweight was 3.42 kilograms, with female babies weighing less on average (3.37 kg) than male babies (3.47 kg)_ and
- _1.8% of full-term  babies were born with a low birthweight (< 2.5 kg)._

In our sample, the median birth weight of girls was `r round(wt_girls / 1000, 2)` kg and the median birth weight of boys was `r round(wt_boys / 1000, 2)` kg. Before drawing any conclusion, we need to find out whether the Ministry used medians or means when they said _average_. But in any case, any difference between our sample and the whole population is likely to be very small.

Now, just for fun, let's compare the birth weight of singletons and twins in the sample. We might predict that, on average, the birth weight of twins would be less than that of singletons. 

```{r, message=FALSE, warning=FALSE, cache=TRUE}

library(ggplot2)
library(RColorBrewer)

# create plot
ggplot(xs, aes(x = cbirth_weight_grams, fill = ctwin)) +
  geom_density(alpha = 0.2) +
  theme_bw() +
  labs(caption = "Source: KidsWords project")
```

That appears to be the case in the plot above. If you compare the R code for this plot and the previous one, only one element is different. In the plot of girls and boys, the ggplot function included the `aesthetic` element, `fill = csex`, while in the plot of twins and singletons, that was changed to `fill = ctwin`. Easy!

Now, let's create a **kernel density plot** of birthweight. 
This time, we'll compare children of different ethnicities. Each respondent was asked on the PQ to identify the child's ethnicity.
Before we create a plot, let's calculate the number of children in each ethnic group using R's `summary` function. 

```{r, message=FALSE, warning=FALSE, cache=TRUE}
summary(xs$cethnicity_nz)
```

As expected, we see that those of New Zealand European descent (Pākehā) and Māori comprised a majority of the children in the sample. Excluding those who didn't report the child's ethnicity (designated in the output above with the category `NA's`), and combining the remaining groups into summary categories used by Stats NZ, we're now ready to make a plot.

Pākehā (New Zealanders of European descent) and Māori babies had different birth weights. Children's ethnicity on the Parent Questionnaire was coded with the variable, `cethnicity_nz`, so we need to find only children from those two ethnic groups in the `xs` data frame for our plot. This is done with `dplyr`'s `filter()` function and the Boolean operator for "or", which is `|`.

In the R script below, let's only select the variables we need, ply each participant's ID code, `PID`, for the plot and put those variables into a separate data frame. You don't have to this, but there's no harm since a data frame is just a virtual **object** that takes up some memory. When we're finished with the new (temporary) data frame, we can remove it from RStudio's Global Environment if we don't need it anymore.

```{r, message=FALSE, warning=FALSE, cache=TRUE}

library(tidyverse)
library(RColorBrewer)

# create new data frame of selected variables
xs_ethnic <- xs %>% 
  select(PID, cbirth_weight_grams, cethnicity_nz)

# duplicate a variable to recode
xs_ethnic <- xs_ethnic %>% 
  mutate(cethnicity_nz2 = cethnicity_nz)

# recode values of duplicate variable using dplyr's old = "new" format
xs_ethnic$cethnicity_nz2 <- recode(xs_ethnic$cethnicity_nz2,
                                   Chinese = "Asian",
                                   Indian = "Asian",
                                   "Cook Island Maori" = "Pacific Peoples",
                                   "Niuean" = "Pacific Peoples",
                                   "Samoan" = "Pacific Peoples",
                                   "Tongan" = "Pacific Peoples")

# remove rows with missing ethnicity data using R's base syntax
xs_ethnic <- xs_ethnic[!is.na(xs_ethnic$cethnicity_nz2), ]

# create density curves using geom_density() 
ggplot(xs_ethnic, aes(x = cbirth_weight_grams, fill = cethnicity_nz2)) +
  geom_density() + #alpha = 0.2
  theme_bw() +
  labs(caption = "Source: KidsWords project")
```

Well, that graph's not terribly informative since the curves overlap so much. 

Let's try another approach, replacing the `geom_density()` function with `geom_line()`, and see what happens.

```{r, message=FALSE, warning=FALSE, cache=TRUE}
# create density curves using geom_line()
ggplot(xs_ethnic, aes(x = cbirth_weight_grams, color = cethnicity_nz2)) +
  geom_line(stat = "density") +
  theme_bw() +
  labs(caption = "Source: KidsWords project")
```

That's more like it. Now we can see the density curve of each ethnic group more clearly, even though they overlap somewhat. 

The reason for going to all this trouble was to have a graph to compare to population-level data from NZ Ministry of Health. (to do...add link or download MoH graph)

## Distribution of vocabulary size by region

Let's create a special kind of boxplot called a **notched boxplot** using the base R function, `boxplot( )` to see whether the distribution of expressive vocabulary differs by region of the country. 

```{r, message=FALSE, warning=FALSE, cache=TRUE}

# create boxplot
boxplot(wordtotal ~ region, data = xs,
        notch = TRUE, col = "cornsilk", range = 1.5,
        ylab = "Vocabulary Size in Words", 
        las = 2)

# Calculate the mean number of words for each month of age
mean_words <- aggregate(wordtotal ~ region, xs, mean)

# Add mean number of words per month to graph
points(mean_words, pch = "*")
```

That did what we wanted but there's clearly a problem with the region labels on the x-axis. The names "Bay of Plenty" and "Manawatu-Wanganui" got clipped. This can be corrected, but I gave up trying. Life is short and labels are sometimes just too long. The `boxplot( )` function works well when the x-axis labels are short, as we'll see when we plot the distribution of vocabulary size by age below, but when the axis labels are long, the code involved to sort things out gets quite wooley.  

Is there a simpler solution? Let's use the `ggplot2` package to find out.

```{r, message=FALSE, warning=FALSE, cache=TRUE}

library(tidyverse)
library(ggplot2)
library(ggthemes)
library(RColorBrewer)

# create boxplot 
ggplot(xs, aes(x = region, y = wordtotal)) + 
  geom_boxplot(notch = TRUE, fill = "cornsilk") + 
  stat_summary(fun.y = "mean", geom = "point", shape = "*", size = 4) +
  labs(x = "\nRegion") +
  theme_few() +  # this must come before next function or else it overrides it
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_y_continuous("Vocabulary Size in Words\n", breaks = seq(0, 700, 100)) + 
  labs(caption = "Source: KidsWords project")
```

That worked beautifully. We adjusted the x-axis labels by 45 degrees and adjusted their height relative to the axis line with `theme(axis.text.x = element_text(angle = 45, hjust = 1)`, illustrating that there's usually more than one way of getting things done with R. Incidentally, the logic behind building a plot using `ggplot2` is based on a "grammar of graphics" (gg) that New Zealander Hadley Wickham developed.

When we look at the notched boxplots, the median vocabulary size of children differs across regions. For example, the median vocabulary size of `r median(filter(xs, region == "Otago")$wordtotal, na.rm = TRUE)` for the Otago region appears to be substantially below that of the Bay of Plenty region (`r median(filter(xs, region == "Bay of Plenty")$wordtotal, na.rm = TRUE)`). The lower limit of the 95% confidence interval for Bay of Plenty appears to be above than the upper limit of the confidence interval for Otago, indicating that the medians are statistically different. This would need to be verified with an appropriate statistical test, of course.

Before jumping to the conclusion that children in Bay of Plenty have larger vocabularies than Otago children because of where they happen to live, which doesn't make sense intuitively, we should explore other possibilities. For example, are the median scores of those regions conditioned (influenced) by things like child sex or maternal education level? In other words, does the proportion of girls and boys differ between those regions? If there are substantially more girls than boys in the Bay of Plenty group of our sample--and if girls as a group have larger vocabularies than boys in early development--then a sex-imbalance between regions in our sample would be a more plausible explanation of the vocabulary size difference than the region itself. Let's find out if this is the case.

The first step is to determine how many girls and boys were sampled in each region.

```{r, message=FALSE, warning=FALSE, cache=TRUE}

library(tidyverse)

# create subset of two regions and select variables to examine
xs$pedcat <- as.factor(xs$pedcat)
xs_sub <- filter(xs, region == "Bay of Plenty" | region == "Otago") 
xs_sub <- select(xs_sub, region, wordtotal, csex, pedcat) 

summary(xs_sub)

# to do

# cross-tabulate region by sex
# table(xs_sub$region, xs_sub$csex)

# cross-tabulate region by pedcat
# table(xs_sub$region, xs_sub$pedcat)

# run a two-way ANOVA
# aov(xs_sub$wordtotal ~ xs$sub$region * xs_sub$csex)
```

## Distribution of vocabulary size by age

Let's give the base R function, `boxplot( )`, another try in making a notched boxplot. But first, a little more on what notched boxplots are. Although I haven't seen these used in child language research, Crawley (2013) and Chang (2019) illustrate them with R code. Notched boxplots visually depict the distribution of values of a dependent variable (e.g., vocabulary size). Group medians are represented by horizontal bars near the middle of each box, with the upper and lower limits of the 95% confidence interval of each median depicted by notches. The notches (confidence interval) of each box look like a waist cinched by a belt (the median). The length of each box represents the interquartile range,  extending from the 25th to 75th percentiles, as they do in garden variety boxplots. Asterisks indicate group means (confidence intervals for means are not represented). The lines extending above and below each box indicate values that are beyond $\pm$ 1.5 times the interquartile range. Circles indicate values beyond that range (outliers). Non-overlapping notches of any two groups give a visual impression of which groups are likely to have significantly different medians. 

```{r, message=FALSE, warning=FALSE, cache=TRUE}

# create boxplot
boxplot(wordtotal ~ camos, data = xs, 
        notch = TRUE, col = "cornsilk", range = 1.5,
        xlab = "Age in Months", ylab = "Vocabulary Size in Words")

# Calculate the mean number of words for each month of age
mean_words <- aggregate(wordtotal ~ camos, xs, mean)

# Add mean number of words per month to graph
points(mean_words$wordtotal, pch = "*")
```

## Sample percentiles for vocabulary size

Percentiles were calculated from the sample data for each month of age and plotted with a **line graph**. (to do: add explanation]

```{r, message=FALSE, warning=FALSE, cache=TRUE}

# calculate sample quantiles 
# based on https://stat.ethz.ch/pipermail/r-help/2011-October/291575.html

# create new data frame from old
xs1 <- xs

# create function to compute quantiles and label each wordtotal;
# use Hyndman and Fan's (1986) quantile algorithm type 8 
q <- function(xs1) {
  qq <- as.data.frame(as.list(quantile(xs1$wordtotal, 
                                       c(.1, .25, .50, .75, .90), type = 8)))
  names(qq) <- paste(c("10th", "25th", "50th", "75th", "90th"), sep = '')
  qq
} 

# apply function to each age group using plyr
# to do: convert plyr code line to tidyverse code)
library(plyr)
qdf <- ddply(xs1, .(camos), q)
head(qdf)
detach("package:plyr")

library(tidyverse)
library(ggthemes)
library(RColorBrewer)

# convert from wide- to long data frame;
# temporary variables (pct, score) created in using gather()
qdflong <- qdf %>% 
  gather(pct, score, -camos) 
head(qdflong)

# plot sample quantiles
ggplot(qdflong, aes(x = factor(camos), y = score, 
                 group = pct, color = pct)) +
  theme_few() +  geom_line() + geom_point() +
  scale_y_continuous(breaks=seq(0, 700, 100)) +
  labs(x = "\nAge in Months", y = "Vocabulary Size in Words\n", 
       colour = "Percentile") +
  scale_colour_brewer(palette = "Dark2", guide = guide_legend(reverse = TRUE)) 
```

## Smoothed percentiles for vocabulary size

This plot uses the `quantregGrowth` package to construct **smoothed (fitted) curves** to model growth in children's expressive vocabulary size from 16- to 30 months of age at the 10th, 25th, 50th, 75th and 90th percentiles. Each curve is accompanied by its 95% confidence interval. In the manuscript, separate plots for girls and boys are presented.
(to do: add explanation for why these tell us something different from line graphs based on sample percentiles]

```{r, message=FALSE, warning=FALSE, cache=TRUE}

library(quantregGrowth)

# define quantiles of interest
tau_set <- c(0.10, 0.25, 0.50, 0.75, 0.90)

# select colors for quantile lines
mypalette <- brewer.pal(5,"Dark2")

# fit quantile curves
# n.boot values used need further exploration
vocab_curves <- gcrq(wordtotal ~ ps(camos, monotone = 1, 
                                    lambda = 100), #n.boot = 100, 
                     data = xs, tau = tau_set)

plot(vocab_curves, conf.level = .95, shade = TRUE,
     # y = TRUE, # uncomment to add data points
     xlab = "Age (months)", 
     ylab = "Vocabulary Size (words produced)",
     legend = TRUE, overlap = TRUE,
     lwd = 2, col = mypalette, lty = 1)
```

## Most frequent words

Inevitably during the course of exploring your data, you might get side-tracked by doing something, well, just because. Everyone needs a few diversions to keep them going, don't they? The following plots are examples of things that occurred to me.

**Word clouds** are useful for visually illustrating a data pattern for a particular purpose. Although I wouldn't use them as a substitute for a quantitative analysis of vocabulary, they're an interesting way to visualise data and might be suitable on a web page, leaflet, etc. We use the `wordcloud` package here to produce a word cloud of the 200 most frequently spoken words by 24-month-olds in the KidsWords project (_N_ = `r nrow(filter(xs, camos == 24))`). This package isn't particularly well documented but there are some helpful examples of scripts for word clouds, network analysis and other things on [STHDA's website](http://www.sthda.com/english/wiki/text-mining-and-word-cloud-fundamentals-in-r-5-simple-steps-you-should-know.)

We start by loading the data in long form, where each row contains each word used by each child, along with other word-level data. We then create a subset of rows from the data frame that we'll use for the word cloud.

```{r, message=FALSE, warning=FALSE, cache=TRUE}

library(tidyverse)

# load files generated by 03_kidswords_dataprep.R
# (need to be loaded here regardless of whether they're already in RStudio's Global Environment)
CDI_words <- readRDS("analysis/data/data_CDI_words.RDS")

# load lookup table of CDI vocabulary characteristics
#word_lookup<- read_csv("data/cdi_lookup.csv")

xs_words <- CDI_words %>% 
  filter(session == 1,  camos >= 16 & camos <= 30)
```

Now we create the word cloud based on certain conditions we've specified in the R code below. We'll only examine words reported to be said (`response == "Says"`) by 24-month-olds (`camos == 24`) from the noun word class (`word_class == "n"`). Once that's done, the script then removes the temporary R objects that are no longer needed.

```{r, message=FALSE, warning=FALSE, cache = TRUE}

library(tidyverse)
library(wordcloud)
library(RColorBrewer)

# filter nouns reported to be said by 24-month-olds
vocab_24 <- filter(xs_words, response == "Says", word_class == "n", camos == 24)

# select only the fields needed further
vocab_24 <- select(vocab_24, CDI_item)

# calculate the number of times each word occurs
vocab_24_counts <- table(vocab_24$CDI_item)

m <- as.matrix(vocab_24_counts)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 20)

# generate the word cloud
wordcloud(words = d$word, freq = d$freq, min.freq = 5,
          max.words = 200, random.order = FALSE, rot.per = 0.35, 
          colors = brewer.pal(8, "Dark2"))

# remove temporary objects no longer needed
rm(vocab_24)
rm(vocab_24_counts)
rm(v)
rm(m)
rm(d)
```

According to the table above the word cloud, the most frequently occurring noun in this sample of 24-month-olds was _bath_. Notice how many times _bath_ occurred compared with the number of 24-month-olds in this age group (_n_ =  `r nrow(filter(xs, camos == 24))`). Therefore, the word _bath_ must have been counted more than once for a large number of children. In fact, _bath_ occurs twice on the NZ CDI:WS, once in the _Furniture and Rooms_ section and once in the _Games and Routines_ section. We discovered that using the code in the next block. Below the code is the output for the word _bath_ and indicates that _bath_ occurs in two different sections of the CDI, coded with the variable `CDI_part`: the _Furniture and Rooms_ section and the _Games and Routines_. As an analyst, you would need to consider whether or not to count multiple instances of the same word form or not. The answer depends on the purpose of your analysis; but for this demonstration, we've counted each occurrence, explaining why the counts for some words exceed the sample size. Whew!

```{r, message=FALSE, warning=FALSE}

library(tidyverse)

# restore the word_lookup data frame
word_lookup <- readRDS("analysis/data/data_word_lookup.RDS")

# find how many times _bath_ occurs in the word_lookup data frame
bath <- filter(word_lookup, CDI_item == "bath")

# display the results
bath
```

## Wh-question development

Let's graph the development of individual wh-question words and examine whether girls differ from boys across the age range. We'll use the `ggplot2` package to do this since it has a handy function for arranging the individual graphs into a single figure (`facet_wrap(~CDI_item)`).

```{r, message=FALSE, warning=FALSE, cache=TRUE}

library(tidyverse)
library(ggplot2)
library(ggthemes)

# select data
wordlist <- xs_words %>%
  select(session, camos, csex, response, resp, field, CDI_item) %>%
  filter(session == "1") %>%
  filter(camos >= 16 & camos <= 30) %>%
  filter(field == 18)

# create age-of-aquisition table
# calculate proportion of kids producing each word by age
AoA_table <- wordlist %>%
  group_by(CDI_item, camos, csex) %>% 
  summarise(prop_said = mean(resp), n = length(resp))

# change table to data frame
AoA_table <- as.data.frame(AoA_table)

# graph each word
ggplot(AoA_table, aes(x = camos, y = prop_said, colour = csex)) +
  theme_light() + 
  geom_line() + 
  geom_point() + 
  scale_x_continuous(name = "\n Age in months", breaks = seq(16, 30, 2)) + 
  scale_y_continuous(name = "Proportion of children\n", limits = c(0, 1), 
                     breaks = seq(0, 1, .2)) +
  facet_wrap( ~ CDI_item) +
  labs (title = "Wh-Question Use (NZ CDI:WS)\n") +
  labs(caption = "Source: KidsWords project")
```

## to be continued...

# About

The final form of many of the plots in this document will appear in a journal article and supplement currently being prepared. That article can be cited as:

Klee, T., Stokes, S.F., Reese, E., Jorgensen, R.N., Bleses, D., Gavin. W.J., & Witchitaksorn, N. (in prep.) Early language development of New Zealand children: national norms for New Zealand English.

Grant support was provided by the Marsden Fund of the Royal Society of New Zealand (UOC1003) and the CDI Advisory Board. The study commenced when authors TK, SFS and NW were at the University the Canterbury, Christchurch, NZ. Work continues at The University of Hong Kong for authors TK and SFS.

![](images/Marsden-logo-rgb-96dpi.jpg){width=250px}
